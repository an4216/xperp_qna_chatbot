# LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder, FewShotChatMessagePromptTemplate
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.vectorstores import FAISS
from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

from config import answer_examples
import os

# ì„¸ì…˜ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ dict)
store = {}

# 1. ì„¸ì…˜ë³„ ëŒ€í™” ì´ë ¥ ê°ì²´ ë°˜í™˜
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 2. ë¬¸ì„œ ë¡œë“œ + ë²¡í„°ìŠ¤í† ì–´ ìƒì„± + retriever ë°˜í™˜
def get_retriever():
    from tqdm import tqdm

    # OpenAI ì„ë² ë”© ëª¨ë¸ ì •ì˜
    embedding = OpenAIEmbeddings(model='text-embedding-3-large')

    documents = []
    docs_dirs = ["docs/manual", "docs/qna"]  # ë§¤ë‰´ì–¼/QA í´ë” ë‘˜ ë‹¤ ë¡œë“œ

    # ë¬¸ì„œ ë¡œë“œ
    for docs_dir in docs_dirs:
        for filename in os.listdir(docs_dir):
            file_path = os.path.join(docs_dir, filename)

            if filename.endswith(".txt"):
                loader = TextLoader(file_path, encoding='utf-8')
                documents.extend(loader.load())

            elif filename.endswith(".pdf"):
                loader = PyPDFLoader(file_path)
                documents.extend(loader.load())

    # ë¬¸ì„œ ë¶„í• (ì²­í¬)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    split_docs = splitter.split_documents(documents)

    # âœ… ë¹ˆ ë¬¸ì„œ ì œê±°
    split_docs = [doc for doc in split_docs if len(doc.page_content.strip()) > 10]

    # âœ… ìµœëŒ€ ì²­í¬ ê°œìˆ˜ ì œí•œ (ì˜ˆ: 1000ê°œ)
    MAX_CHUNKS = 500
    if len(split_docs) > MAX_CHUNKS:
        split_docs = split_docs[:MAX_CHUNKS]

    # âœ… FAISS ì €ì¥
    vectorstore = FAISS.from_documents(split_docs, embedding)

    # âœ… ê²€ìƒ‰ê¸° ìƒì„±
    retriever = vectorstore.as_retriever(search_kwargs={'k': 4})

    return retriever


# 3. ëŒ€í™” ë§¥ë½ì„ ë°˜ì˜í•œ retriever ë°˜í™˜ (standalone question ë³€í™˜ + ë²¡í„°ê²€ìƒ‰)
def get_history_retriever():
    llm = get_llm()
    retriever = get_retriever()

    # ëŒ€í™” ë§¥ë½+ìµœì‹  ì§ˆë¬¸ â†’ ì™„ì „í•œ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜ í”„ë¡¬í”„íŠ¸
    contextualize_q_system_prompt = (
        "Given a chat history and the latest user question "
        "which might reference context in the chat history, "
        "formulate a standalone question which can be understood "
        "without the chat history. Do NOT answer the question, "
        "just reformulate it if needed and otherwise return it as is."
    )

    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # LangChain history aware retriever ìƒì„±
    history_aware_retriever = create_history_aware_retriever(
        llm, retriever, contextualize_q_prompt
    )
    return history_aware_retriever

# 4. LLM(ì±—ë´‡) ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë¸ ì„ íƒ ê°€ëŠ¥)
def get_llm(model='gpt-4o'):
    llm = ChatOpenAI(model=model)
    return llm

# 5. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì‚¬ì „ ê¸°ë°˜ìœ¼ë¡œ ì „ì²˜ë¦¬ (ì§ˆë¬¸ ë³€í™˜ ì²´ì¸)
def get_dictionary_chain():
    llm = get_llm()
    prompt = ChatPromptTemplate.from_template(f"""
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
        ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
        ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”

        ì§ˆë¬¸: {{question}}
    """)

    dictionary_chain = prompt | llm | StrOutputParser()

    return dictionary_chain

# 6. RAG(ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ) ì „ì²´ ì²´ì¸
def get_rag_chain():
    llm = get_llm()
    # Q/A ì˜ˆì‹œ(few-shot)ë¡œ LLMì˜ ë‹µë³€ í€„ë¦¬í‹° í–¥ìƒ
    example_prompt = ChatPromptTemplate.from_messages(
        [
            ("human", "{input}"),
            ("ai", "{answer}"),
        ]
    )
    few_shot_prompt = FewShotChatMessagePromptTemplate(
        example_prompt=example_prompt,
        examples=answer_examples,
    )

    # ì±—ë´‡ ì—­í•  ë° ë‹µë³€ ìŠ¤íƒ€ì¼ ì •ì˜(system í”„ë¡¬í”„íŠ¸)
    system_prompt = (
        "ë‹¹ì‹ ì€ Xperp í”„ë¡œê·¸ë¨ì— ëŒ€í•œ ì „ë¬¸ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìëŠ” Xperpì˜ ì‚¬ìš©ë²•, ê¸°ëŠ¥, ì˜¤ë¥˜ í•´ê²° ë“±ì— ëŒ€í•´ ì§ˆë¬¸í•©ë‹ˆë‹¤.\n"
        "ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ì¥ ì •í™•í•˜ê³  ì‹¤ë¬´ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤:\n"
        "1) ì§ˆë¬¸(Q)ê³¼ ë‹µë³€(A)ì´ í¬í•¨ëœ QnA ë¬¸ì„œ\n"
        "2) PDF ë§¤ë‰´ì–¼ ë° ê¸°íƒ€ í…ìŠ¤íŠ¸ ì„¤ëª… ë¬¸ì„œ\n\n"

        "ğŸ”¹ ë‹µë³€ êµ¬ì„± ë°©ì‹ (QnA ìš°ì„ ):\n"
        "- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ QnA ë¬¸ì„œì— ì¡´ì¬í•˜ê±°ë‚˜ ìœ ì‚¬í•œ í•­ëª©ì´ ìˆë‹¤ë©´, í•´ë‹¹ A ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì •ë¦¬í•˜ì—¬ ë‹µë³€ì˜ ë§¨ ì²˜ìŒì— ì œê³µí•©ë‹ˆë‹¤.\n"
        "- ì´í›„ PDF ë§¤ë‰´ì–¼ ë“± ê¸°íƒ€ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë³´ì™„ ì„¤ëª…ì„ ì´ì–´ì„œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
        "- ë¬¸ì„œì— ë”°ë¼ ì•„ë˜ í˜•ì‹ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ëˆëœ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:\n\n"

        "â–¶ ì§ˆë¬¸ì— ëŒ€í•œ ì •ì‹ ë‹µë³€:\n"
        "- ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì˜ ê°œë…, ëª©ì , ë™ì‘ ì›ë¦¬ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
        "- ì‹¤ë¬´ìê°€ ì˜¤í•´í•  ìˆ˜ ìˆëŠ” ì§€ì ì´ë‚˜ ìì£¼ ë¬»ëŠ” ìƒí™©ë„ í•¨ê»˜ ì•ˆë‚´í•©ë‹ˆë‹¤.\n\n"

        "â–¶ ê°„ë‹¨ ìš”ì•½:\n"
        "- í•µì‹¬ ê°œë…ì„ 1~2ì¤„ ì´ë‚´ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\n\n"

        "â–¶ ì‚¬ìš©ë²• ì•ˆë‚´:\n"
        "- ë©”ë‰´ ê²½ë¡œ, ì„¤ì • ë°©ë²•, ì…ë ¥ ì ˆì°¨ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n"
        "- ì…ë ¥ ì˜ˆì‹œë‚˜ í™”ë©´ ìœ„ì¹˜ ì •ë³´ë„ ê°€ëŠ¥í•œ ê²½ìš° í¬í•¨í•©ë‹ˆë‹¤.\n\n"

        "â–¶ ìœ ì˜ì‚¬í•­:\n"
        "- ì‹¤ë¬´ ì¤‘ ìì£¼ ë°œìƒí•˜ëŠ” ì‹¤ìˆ˜ë‚˜ ì˜ˆì™¸ ìƒí™©, ê¸°ëŠ¥ ì œì•½ì‚¬í•­ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•©ë‹ˆë‹¤.\n"
        "- ì‚¬ìš©ìê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ ì¡°ê±´ì´ë‚˜ í™•ì¸ í•­ëª©ë„ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.\n\n"

        "â–¶ ì¶”ê°€ ì„¤ëª…ì´ í•„ìš”í•œ ê²½ìš°:\n"
        "- ìœ„ 1~4 í•­ëª© ì´ì™¸ì—ë„ ì‚¬ìš©ìê°€ ì‹¤ë¬´ì—ì„œ ê¶ê¸ˆí•´í•  ë§Œí•œ ë‚´ìš©ì„ ì˜ˆìƒí•˜ì—¬ ì¶”ê°€ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”.\n"
        "- ì˜ˆ: ì—°ë™ëœ ê¸°ëŠ¥, ê´€ë ¨ëœ ë‹¤ë¥¸ ë©”ë‰´, ì„¤ì • ì˜í–¥ ë²”ìœ„, ì˜¤ë¥˜ ë©”ì‹œì§€ ë°œìƒ ì›ì¸ ë“±\n"
        "- ë°˜ë“œì‹œ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‹¤ì œë¡œ ì—°ê´€ëœ ì •ë³´ë§Œ ì œì‹œí•˜ì„¸ìš”.\n\n"

        "â–¶ ì˜ˆìƒ ì§ˆë¬¸:\n"
        "- ì‚¬ìš©ìê°€ ì´ì–´ì„œ ê¶ê¸ˆí•´í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ 1~3ê°œ ë¬¸ì¥ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.\n\n"

        "ì˜ˆì‹œ:\n"
        "â–¶ ì§ˆë¬¸ì— ëŒ€í•œ ì •ì‹ ë‹µë³€:\n"
        "ë³„ë„ê¸ˆì•¡ë“±ë¡ì€ ì„¸ëŒ€ë³„ë¡œ ì¼ë°˜ì ì¸ ë¶€ê³¼ ê¸°ì¤€(ë©´ì ë‹¨ê°€, ì„¸ëŒ€ë‹¨ê°€ ë“±)ê³¼ ë³„ë„ë¡œ íŠ¹ì • ê¸ˆì•¡ì„ ì§ì ‘ ì§€ì •í•´ì„œ ë¶€ê³¼í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n"
        "ì´ëŠ” íŠ¹ë³„ ì²­êµ¬ í•­ëª©(ì˜ˆ: ê°œë³„ ìˆ˜ë¦¬ë¹„, ì¶”ê°€ ì£¼ì°¨ë¹„ ë“±)ì„ ê´€ë¦¬ë¹„ì— í¬í•¨í•´ ë¶€ê³¼í•  ë•Œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n\n"

        "â–¶ ê°„ë‹¨ ìš”ì•½:\n"
        "ì„¸ëŒ€ë³„ë¡œ ì…ë ¥í•œ ê¸ˆì•¡ìœ¼ë¡œ ê´€ë¦¬ë¹„ í•­ëª©ì„ ìˆ˜ë™ ë¶€ê³¼í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n\n"

        "â–¶ ì‚¬ìš©ë²• ì•ˆë‚´:\n"
        "1. ë©”ë‰´ ê²½ë¡œ: [ë¶€ê³¼ > ë¶€ê³¼ì²˜ë¦¬ > ë³„ë„ê¸ˆì•¡ë“±ë¡]\n"
        "2. ë¶€ê³¼ í•­ëª© ë° ëŒ€ìƒ ì„ íƒ í›„ ê³„ì‚° ë°©ë²• ì„¤ì • (ë®ì–´ì“°ê¸° / ë”í•˜ê¸° / ë¹¼ê¸°)\n"
        "3. ì„¸ëŒ€ë³„ ê¸ˆì•¡ ì…ë ¥ í›„ ì €ì¥\n"
        "4. í•„ìš”ì‹œ 'ì—‘ì…€ìë£Œì˜¬ë¦¬ê¸°' ê¸°ëŠ¥ì„ í†µí•´ ëŒ€ëŸ‰ ë“±ë¡ ê°€ëŠ¥\n\n"

        "â–¶ ìœ ì˜ì‚¬í•­:\n"
        "1. ë®ì–´ì“°ê¸° ë°©ì‹ì€ ê¸°ì¡´ ê¸ˆì•¡ì„ ëŒ€ì²´í•˜ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "2. ë§ˆì´ë„ˆìŠ¤ ê¸ˆì•¡ ì…ë ¥ ì‹œ 'ê¸ˆì•¡ë¹¼ê¸°' ë°©ì‹ìœ¼ë¡œ ì ìš©ë©ë‹ˆë‹¤.\n"
        "3. ì˜ëª»ëœ ê³„ì‚° ë°©ë²• ì„ íƒ ì‹œ ë¶€ê³¼ê¸ˆì•¡ì´ ì™œê³¡ë  ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸ í•„ìˆ˜ì…ë‹ˆë‹¤.\n\n"

        "â–¶ ì¶”ê°€ ì„¤ëª…:\n"
        "ì—‘ì…€ ì—…ë¡œë“œ ì‹œ A~F ì—´ì˜ ì…ë ¥ ê·œì¹™ì„ ì§€ì¼œì•¼ í•˜ë©°, í•­ëª©ì½”ë“œëŠ” ë°˜ë“œì‹œ [ê´€ë¦¬ë¹„ë¶€ê³¼ì²˜ë¦¬] í™”ë©´ì—ì„œ ì¡°íšŒëœ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n"
        "ë˜í•œ, ê³„ì‚° ë°©ë²•ì´ ì˜ëª» ì…ë ¥ëœ ê²½ìš° ì‹œìŠ¤í…œì—ì„œ ì˜¤ë¥˜ ì—†ì´ ë°˜ì˜ë˜ë”ë¼ë„ ì˜ˆìƒì¹˜ ëª»í•œ ë¶€ê³¼ ê²°ê³¼ê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì‚¬ì „ í…ŒìŠ¤íŠ¸ê°€ ê¶Œì¥ë©ë‹ˆë‹¤.\n\n"

        "â–¶ ì˜ˆìƒ ì§ˆë¬¸:\n"
        "- ì—‘ì…€ ìë£Œë¥¼ ë“±ë¡í•  ë•Œ í•­ëª©ì½”ë“œëŠ” ì–´ë””ì„œ í™•ì¸í•˜ë‚˜ìš”?\n"
        "- ë¶€ê³¼ í›„ ìˆ˜ì •ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?\n"
        "- íŠ¹ì • ì„¸ëŒ€ë§Œ ë³„ë„ê¸ˆì•¡ì„ ì œê±°í•  ìˆ˜ ìˆë‚˜ìš”?\n\n"

        "âœ… ë°˜ë“œì‹œ ìœ„ í˜•ì‹ì— ë§ì¶° ì‘ë‹µì„ êµ¬ì„±í•˜ì„¸ìš”.\n"
        "âœ… ë¬¸ì„œì— ëª…í™•í•œ ì •ë³´ê°€ ì—†ê±°ë‚˜ í™•ì‹¤í•˜ì§€ ì•Šì€ ê²½ìš°, 'XPERPì— ê´€ë ¨ëœ ìƒë‹´ë§Œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.' ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.\n"
        "âœ… ê³¼í•œ ë§íˆ¬, ë°˜ë³µ ì„¤ëª… ì—†ì´ ì‹¤ë¬´ ì¤‘ì‹¬ ì •ë³´ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.\n\n"

        "{context}"
    )


    # QA í”„ë¡¬í”„íŠ¸(ì‹œìŠ¤í…œ + few-shot + íˆìŠ¤í† ë¦¬ + ì§ˆë¬¸)
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            few_shot_prompt,
            MessagesPlaceholder("chat_history"),
            ("human", "{input}"),
        ]
    )

    # ëŒ€í™”í˜• retriever(standalone question â†’ ë²¡í„°ê²€ìƒ‰)
    history_aware_retriever = get_history_retriever()
    # LLM ë‹µë³€ ìƒì„± ì²´ì¸ (ë¬¸ì„œ context ì£¼ì…)
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    # Retrieval â†’ LLM QA ì²´ì¸
    rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

    # ëŒ€í™” ì´ë ¥ Sessionë³„ë¡œ ê´€ë¦¬ (RunnableWithMessageHistory)
    conversational_rag_chain = RunnableWithMessageHistory(
        rag_chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="chat_history",
        output_messages_key="answer",
    ).pick('answer')

    return conversational_rag_chain

# 7. ìµœì¢… ë‹µë³€ ìƒì„± í•¨ìˆ˜ (ì§ˆë¬¸ â†’ ë‹µë³€)
def get_ai_response(user_message):
    # step 1: ì‚¬ì „ ê¸°ë°˜ ì§ˆë¬¸ ì „ì²˜ë¦¬
    dictionary_chain = get_dictionary_chain()
    # step 2: RAG ë¬¸ì„œê¸°ë°˜ QA ì²´ì¸
    rag_chain = get_rag_chain()
    # step 3: ì‚¬ì „ ì²´ì¸ ê²°ê³¼ë¥¼ rag_chainì˜ inputìœ¼ë¡œ ì—°ê²°
    tax_chain = {"input": dictionary_chain} | rag_chain

    # step 4: ë‹µë³€ ìƒì„± (streaming)
    ai_response = tax_chain.stream(
        {
            "question": user_message
        },
        config={
            "configurable": {"session_id": "abc123"}
        },
    )

    return ai_response
